<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<HTML
><HEAD
><TITLE
>Сравнение различных решений</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.79"><LINK
REV="MADE"
HREF="mailto:pgsql-docs@postgresql.org"><LINK
REL="HOME"
TITLE="Документация по PostgreSQL 9.4.1"
HREF="index.html"><LINK
REL="UP"
TITLE="Отказоустойчивость, балансировка нагрузки и репликация"
HREF="high-availability.html"><LINK
REL="PREVIOUS"
TITLE="Отказоустойчивость, балансировка нагрузки и репликация"
HREF="high-availability.html"><LINK
REL="NEXT"
TITLE="Трансляция журналов на резервные серверы"
HREF="warm-standby.html"><LINK
REL="STYLESHEET"
TYPE="text/css"
HREF="stylesheet.css"><META
HTTP-EQUIV="Content-Type"
CONTENT="text/html; charset=UTF-8"><META
NAME="creation"
CONTENT="2016-04-12T07:56:57"></HEAD
><BODY
CLASS="SECT1"
><DIV
CLASS="NAVHEADER"
><TABLE
SUMMARY="Header navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TH
COLSPAN="4"
ALIGN="center"
VALIGN="bottom"
><A
HREF="index.html"
>Документация по PostgreSQL 9.4.1</A
></TH
></TR
><TR
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="top"
><A
TITLE="Отказоустойчивость, балансировка нагрузки и репликация"
HREF="high-availability.html"
ACCESSKEY="P"
>Пред.</A
></TD
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="top"
><A
HREF="high-availability.html"
ACCESSKEY="U"
>Уровень выше</A
></TD
><TD
WIDTH="60%"
ALIGN="center"
VALIGN="bottom"
>Глава 25. Отказоустойчивость, балансировка нагрузки и репликация</TD
><TD
WIDTH="20%"
ALIGN="right"
VALIGN="top"
><A
TITLE="Трансляция журналов на резервные серверы"
HREF="warm-standby.html"
ACCESSKEY="N"
>След.</A
></TD
></TR
></TABLE
><HR
ALIGN="LEFT"
WIDTH="100%"></DIV
><DIV
CLASS="SECT1"
><H1
CLASS="SECT1"
><A
NAME="DIFFERENT-REPLICATION-SOLUTIONS"
>25.1. Сравнение различных решений</A
></H1
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
>Отказоустойчивость на разделяемых дисках</DT
><DD
><P
>Отказоустойчивость на разделяемых дисках позволяет избежать избыточности синхронизации путём задействования только одной копии базы данных. Она использует единственный дисковый массив, который разделяется между несколькими серверами. Если основной сервер БД откажет, резервный сервер может подключиться и запустить базу данных, что позволит восстановить БД после аварии. Это обеспечивает быстрое переключение без потери данных.</P
><P
>Функциональность разделяемого оборудования обычно реализована в сетевых устройствах хранения. Так же возможно применение сетевой файловой системы, особое внимание следует уделить тому, чтобы поведение системы полностью соответствовало <ACRONYM
CLASS="ACRONYM"
>POSIX</ACRONYM
> (см. <A
HREF="creating-cluster.html#CREATING-CLUSTER-NFS"
>Подраздел 17.2.1</A
>). Существенное ограничение этого метода состоит в том, что в случае отказа или порчи разделяемого дискового массива оба сервера: ведущий и резервный — станут нерабочими. Другая особенность — резервный сервер никогда не получает доступ к разделяемым дискам во время работы ведущего.</P
></DD
><DT
>Репликация на уровне файловой системы (блочного устройства)</DT
><DD
><P
>Видоизменённая версия функциональности разделяемого оборудования представлена в виде репликации на уровне файловой системы, когда все изменения в файловой системе отражаются в файловой системе другого компьютера. Единственное ограничение: синхронизация должна выполняться методом, гарантирующим целостность копии файловой системы на резервном сервере &mdash; в частности, запись на резервном сервере должна происходить в том же порядке, что и на главном. <SPAN
CLASS="PRODUCTNAME"
>DRBD</SPAN
> является популярным решением на основе репликации файловой системы для Linux.</P
></DD
><DT
>Трансляция журнала транзакций</DT
><DD
><P
>Серверы тёплого и горячего резерва могут так же поддерживаться актуальными путём чтения потока записей из журнала изменений (<ACRONYM
CLASS="ACRONYM"
>WAL</ACRONYM
>). Если основной сервер отказывает, резервный содержит почти все данные с него и может быть быстро преобразован в новый главный сервер БД. Это можно сделать синхронно или асинхронно, но может быть выполнено только на уровне сервера БД целиком.</P
><P
>Резервный сервер может быть реализован с применением трансляции файлов журналов (см. <A
HREF="warm-standby.html"
>Раздел 25.2</A
>), или потоковой репликации (см. <A
HREF="warm-standby.html#STREAMING-REPLICATION"
>Подраздел 25.2.5</A
>), или их комбинацией. За информацией о горячем резерве обратитесь к <A
HREF="hot-standby.html"
>Разделу 25.5</A
>.</P
></DD
><DT
>Репликация главный-резервный на основе триггеров</DT
><DD
><P
>При репликации главный-резервный все запросы, изменяющие данные, пересылаются главному серверу. Главный сервер, в свою очередь, асинхронно пересылает изменённые данные резервному. Резервный сервер может обрабатывать запросы только на чтение при работающем главном. Такой резервный сервер идеален для обработки запросов к хранилищам данных.</P
><P
><SPAN
CLASS="PRODUCTNAME"
>Slony-I</SPAN
> является примером подобного типа репликации, действующей на уровне таблиц, и поддерживает множество резервных серверов. Так как обновления на резервных серверах происходят асинхронно (в пакетах), возможна потеря данных во время отказа.</P
></DD
><DT
>Репликация запросов в среднем слое</DT
><DD
><P
>В схеме с репликацией запросов в среднем слое, средний слой перехватывает каждый SQL-запрос и пересылает его на один или все серверы. Каждый сервер работает независимо. Модифицирующие запросы должны быть направлены всем серверам, чтобы каждый из них получал все изменения. Но читающие запросы могут быть посланы только на один сервер, что позволяет перераспределить читающую нагрузку между всеми серверами.</P
><P
>Если запросы просто перенаправлять без изменений, функции подобные <CODE
CLASS="FUNCTION"
>random()</CODE
>, <CODE
CLASS="FUNCTION"
>CURRENT_TIMESTAMP</CODE
> и последовательности могут получить различные значения на разных серверах. Это происходит потому что каждый сервер работает независимо, а эти запросы неизбирательные (и действительно не изменяют строки). Если такая ситуация недопустима, или средний слой, или приложение должно запросить подобные значения с одного сервера, затем использовать его в других пишущих запросах. Другим способом является применения этого вида репликации совместно с другим традиционным набором репликации главный-резервный, то есть изменяющие данные запросы посылаются только на главный сервер, а затем применяются на резервном в процессе этой репликации, но не с помощью реплицирующего среднего слоя. Следует иметь в виду, что все транзакции фиксируются или прерываются на всех серверах, возможно с применением двухфазной фиксации (см. <A
HREF="sql-prepare-transaction.html"
>PREPARE TRANSACTION</A
> и <A
HREF="sql-commit-prepared.html"
>COMMIT PREPARED</A
>). Репликацию такого типа реализуют, например <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> и <SPAN
CLASS="PRODUCTNAME"
>Continuent Tungsten</SPAN
>.</P
></DD
><DT
>Асинхронная репликация с несколькими главными серверами</DT
><DD
><P
>Если серверы не находятся постоянно в единой сети, как например, ноутбуки или удалённые серверы, обеспечение согласованности данных между ними представляет проблему. Когда используется асинхронная репликация с несколькими главными серверами, каждый из них работает независимо и периодически связывается с другими серверами для определения конфликтующих транзакций. Конфликты могут урегулироваться пользователем или по правилам их разрешения. Примером такого типа репликации является Bucardo.</P
></DD
><DT
>Синхронная репликация с несколькими главными серверами</DT
><DD
><P
>При синхронной репликации с несколькими главными серверами каждый сервер может принимать запросы на запись, а изменённые данные передаются с начального сервера всем остальным, прежде чем транзакция будет подтверждена. Если запись производится интенсивно, это может провоцировать избыточные блокировки, что приводит к снижению производительности. На самом деле производительность при записи часто бывает хуже, чем с одним сервером. Запросы на чтение также могут быть обработаны любым сервером. В некоторых конфигурациях для более эффективного взаимодействия серверов применяются разделяемые диски. Синхронная репликация с несколькими главными серверами лучше всего работает, когда преобладают операции чтения, хотя её большой плюс в том, что любой сервер может принимать запросы на запись &mdash; нет необходимости искусственно разделять нагрузку между главным и резервными серверами, а так как изменения передаются от одного сервера другим, не возникает проблем с недетерминированными функциями вроде <CODE
CLASS="FUNCTION"
>random()</CODE
>.</P
><P
><SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> не предоставляет данный тип репликации, но так как <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> поддерживает двухфазное подтверждение транзакции (<A
HREF="sql-prepare-transaction.html"
>PREPARE TRANSACTION</A
> и <A
HREF="sql-commit-prepared.html"
>COMMIT PREPARED</A
>) такое поведение может быть реализовано в коде приложения или среднего слоя.</P
></DD
><DT
>Коммерческие решения</DT
><DD
><P
>Так как <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> обладает открытым кодом и легко расширяется, некоторые компании взяли за основу <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> и создали коммерческие решения с закрытым кодом со своими реализациями свойств отказоустойчивости, репликации и балансировки нагрузки.</P
></DD
></DL
></DIV
><P
><A
HREF="different-replication-solutions.html#HIGH-AVAILABILITY-MATRIX"
>Таблица 25-1</A
> итоговая таблица возможностей различных решений приведена ниже.</P
><DIV
CLASS="TABLE"
><A
NAME="HIGH-AVAILABILITY-MATRIX"
></A
><P
><B
>Таблица 25-1. Таблица свойств отказоустойчивости, балансировки нагрузки и репликации</B
></P
><TABLE
BORDER="1"
CLASS="CALSTABLE"
><COL><COL><COL><COL><COL><COL><COL><COL><THEAD
><TR
><TH
>Тип</TH
><TH
>Отказоустойчивость через разделяемые диски</TH
><TH
>Репликация файловой системы</TH
><TH
>Трансляция журнала транзакций</TH
><TH
>Репликация главный-резервный на основе триггеров</TH
><TH
>Репликация запросов в среднем слое</TH
><TH
>Асинхронная репликация с несколькими главными серверами</TH
><TH
>Синхронная репликация с несколькими главными серверами</TH
></TR
></THEAD
><TBODY
><TR
><TD
>Наиболее типичная реализация</TD
><TD
ALIGN="CENTER"
>NAS</TD
><TD
ALIGN="CENTER"
>DRBD</TD
><TD
ALIGN="CENTER"
>Потоковая репликация</TD
><TD
ALIGN="CENTER"
>Slony</TD
><TD
ALIGN="CENTER"
>pgpool-II</TD
><TD
ALIGN="CENTER"
>Bucardo</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
></TR
><TR
><TD
>Метод взаимодействия</TD
><TD
ALIGN="CENTER"
>разделяемые диски</TD
><TD
ALIGN="CENTER"
>дисковые блоки</TD
><TD
ALIGN="CENTER"
>WAL</TD
><TD
ALIGN="CENTER"
>Строки таблицы</TD
><TD
ALIGN="CENTER"
>SQL</TD
><TD
ALIGN="CENTER"
>Строки таблицы</TD
><TD
ALIGN="CENTER"
>Строки таблицы и блокировки строк</TD
></TR
><TR
><TD
>Не требуется специального оборудования</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
></TR
><TR
><TD
>Допускается несколько главных серверов</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
></TR
><TR
><TD
>Нет избыточности главного сервера</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
></TR
><TR
><TD
>Нет задержки при нескольких серверах</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>без синхр.</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
></TR
><TR
><TD
>Отказ главного сервера не может привести к потере данных</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>с синхр.</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
></TR
><TR
><TD
>Резервный сервер принимает читающие запросы</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>с горячим резервом</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
></TR
><TR
><TD
>Репликация на уровне таблиц</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
></TR
><TR
><TD
>Не требуется разрешение конфликтов</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&nbsp;</TD
><TD
ALIGN="CENTER"
>&bull;</TD
></TR
></TBODY
></TABLE
></DIV
><P
>Несколько решений, которые не подпадают под указанные выше категории:</P
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
>Секционирование данных</DT
><DD
><P
>При секционировании таблицы расщепляются на наборы данных. Каждый из наборов может быть изменён только на одном сервере. Например, данные могут быть секционированы по офисам, например, Лондон и Париж, с сервером в каждом офисе. В случае необходимости обращения одновременно к данным Лондона и Парижа, приложение может запросить оба сервера, или может быть применена репликация главный-резервный для предоставления копии только для чтения в другом офисе для каждого из серверов.</P
></DD
><DT
>Выполнение параллельных запросов на нескольких серверах</DT
><DD
><P
>Многие из указанных выше решений позволяют обрабатывать несколько запросов на нескольких серверах, но ни один из них не может обрабатывать один запрос с применением нескольких серверов для уменьшения общего времени выполнения. Подобное решение позволяет нескольким серверам обрабатывать один запрос одновременно. Такое обычно достигается путём разделения данных между серверами, обработкой на сервере своей части запроса с возвратом результата на центральный сервер. Там данные проходят окончательную обработку и возвращаются пользователю. <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> предоставляет такую возможность. Так же это может быть реализовано с применением набора средств <SPAN
CLASS="PRODUCTNAME"
>PL/Proxy</SPAN
>.</P
></DD
></DL
></DIV
></DIV
><DIV
CLASS="NAVFOOTER"
><HR
ALIGN="LEFT"
WIDTH="100%"><TABLE
SUMMARY="Footer navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
><A
HREF="high-availability.html"
ACCESSKEY="P"
>Пред.</A
></TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="index.html"
ACCESSKEY="H"
>Начало</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
><A
HREF="warm-standby.html"
ACCESSKEY="N"
>След.</A
></TD
></TR
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
>Отказоустойчивость, балансировка нагрузки и репликация</TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="high-availability.html"
ACCESSKEY="U"
>Уровень выше</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
>Трансляция журналов на резервные серверы</TD
></TR
></TABLE
></DIV
></BODY
></HTML
>